import requests
from bs4 import BeautifulSoup
import csv
import re
import os
import sys
import time
import random

# --- ì¶”ì²œ í•„í„°ë§ í‚¤ì›Œë“œ (ì—„ë§ˆ ì¶”ì²œ & ê±´ìš° ì·¨í–¥ ì €ê²©) ---
# 7ì‚´ ì•„ë“¤ ê±´ìš°ê°€ ì¢‹ì•„í•˜ëŠ” ê³¤ì¶©, ìƒë¬¼ ê´€ë ¨ í‚¤ì›Œë“œì™€ êµìœ¡ìš©í’ˆ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.
RECOMMENDED_KEYWORDS = [
    # ê±´ìš° ë§ì¶¤í˜• í‚¤ì›Œë“œ (ê³¤ì¶©/ìƒë¬¼/ê³¼í•™/í”¼ê·œì–´)
    'ì‚¬ìŠ´ë²Œë ˆ', 'ì¥ìˆ˜í’ë…ì´', 'ê³¤ì¶©', 'ìƒë¬¼', 'ë„ê°', 'íŒŒë¸Œë¥´', 'í‘œë³¸', 'ê³¼í•™ì¡ì§€', 
    'ë‚´ì…”ë„ì§€ì˜¤ê·¸ë˜í”½', 'ìì—°ê´€ì°°', 'ê´€ì°°í‚¤íŠ¸', 'í˜„ë¯¸ê²½', 'ë‹ë³´ê¸°', 'ë ˆê³ ', 'í”¼ê·œì–´', 'ê³µë£¡',
    # ìœ ì•„/í•™ìƒ êµìœ¡ìš© í‚¤ì›Œë“œ
    'ìœ ì¹˜ì›', 'ì´ˆë“±í•™êµ', 'ì¤‘í•™êµ', 'ê³ ë“±í•™ìƒ', 'ì…í•™', 'ì‹ í•™ê¸°', 'ì–´ë¦°ì´ë‚ ',
    'ì¥ë‚œê°', 'êµêµ¬', 'í•™ìš©í’ˆ', 'í•„ê¸°êµ¬', 'ë°±íŒ©', 'ì±…ê°€ë°©', 'ë¬¸ì œì§‘', 'ì°¸ê³ ì„œ',
    'íƒœë¸”ë¦¿', 'ì•„ì´íŒ¨ë“œ', 'ê°¤ëŸ­ì‹œíƒ­', 'ì¸ê°•ìš©', 'ë…¸íŠ¸ë¶', 'ìš´ë™í™”', 'íŠ¸ë ˆì´ë‹ë³µ'
]

def get_platform_color(platform):
    """í”Œë«í¼ ì´ë¦„ì— ë”°ë¼ í…Œë§ˆ ìƒ‰ìƒì„ ê²°ì •í•©ë‹ˆë‹¤."""
    p = platform.lower()
    if 'ì¿ íŒ¡' in p: return 'red'
    if 'ë„¤ì´ë²„' in p or 'nì‡¼í•‘' in p: return 'green'
    if '11ë²ˆê°€' in p or 'gë§ˆì¼“' in p or 'ì§€ë§ˆì¼“' in p or 'ì˜¥ì…˜' in p: return 'red'
    return 'blue'

def extract_price(title):
    """ì œëª© ë¬¸ìì—´ì—ì„œ ê°€ê²© ìˆ«ìë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤ (ë‹¤ì–‘í•œ íŒ¨í„´ ëŒ€ì‘)."""
    # 1. 'ìˆ«ìì›' í˜•íƒœ íƒìƒ‰ (ì˜ˆ: 15,900ì›)
    match = re.search(r'([\d,]+)\s*ì›', title)
    if match:
        price_str = match.group(1).replace(',', '')
        if price_str.isdigit():
            return int(price_str)
            
    # 2. 'ì›'ì´ ì—†ì–´ë„ 3ìë¦¬ ì´ìƒì˜ ìˆ«ì ì½¤ë§ˆ íŒ¨í„´ íƒìƒ‰ (ì˜ˆ: 15,900)
    match = re.search(r'([\d]{1,3}(?:,[\d]{3})+)', title)
    if match:
        price_str = match.group(1).replace(',', '')
        return int(price_str)
        
    return 0

def get_soup(url, session):
    """ì§€ì •ëœ URLì— ì ‘ì†í•˜ì—¬ BeautifulSoup ê°ì²´ë¥¼ ë°˜í™˜í•˜ë©°, ìƒì„¸ ë¡œê·¸ë¥¼ ë‚¨ê¹ë‹ˆë‹¤."""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8',
        'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
        'Referer': 'https://www.google.com/',
        'Cache-Control': 'no-cache',
        'Sec-Ch-Ua': '"Google Chrome";v="131", "Chromium";v="131", "Not_A Brand";v="24"',
        'Sec-Ch-Ua-Mobile': '?0',
        'Sec-Ch-Ua-Platform': '"Windows"',
        'DNT': '1'
    }
    
    try:
        print(f"DEBUG: {url} ì ‘ì† ì‹œë„ ì¤‘...")
        response = session.get(url, headers=headers, timeout=25)
        
        # ë½ë¿Œ íŠ¹ìœ ì˜ euc-kr ì¸ì½”ë”© ê°•ì œ ì²˜ë¦¬
        if response.encoding and response.encoding.lower() == 'iso-8859-1':
            response.encoding = 'euc-kr'
        elif not response.encoding or response.encoding.lower() == 'utf-8':
            response.encoding = 'euc-kr'
            
        if response.status_code != 200:
            print(f"âš ï¸ {url} ì ‘ì† ì‹¤íŒ¨ (ìƒíƒœ ì½”ë“œ: {response.status_code})")
            return None, ""

        return BeautifulSoup(response.text, 'html.parser'), response.text
    except Exception as e:
        print(f"âŒ ì ‘ì† ì˜¤ë¥˜ ë°œìƒ ({url}): {e}")
        return None, ""

def collect_from_ppomppu():
    """ë½ë¿Œ í•«ë”œ ê²Œì‹œíŒ ìˆ˜ì§‘ (ë°ìŠ¤í¬í†±/ëª¨ë°”ì¼ ë‹¤ì¤‘ ì‹œë„)"""
    session = requests.Session()
    urls = [
        "https://www.ppomppu.co.kr/zboard/zboard.php?id=ppomppu", # PC ë²„ì „
        "https://m.ppomppu.co.kr/new/bbs_list.php?id=ppomppu"     # ëª¨ë°”ì¼ ë²„ì „
    ]
    
    collected_data = []

    for url in urls:
        print(f"\nğŸŒ í˜„ì¬ ìˆ˜ì§‘ ëŒ€ìƒ: {url}")
        soup, html_raw = get_soup(url, session)
        
        if not soup:
            continue

        # ì°¨ë‹¨ ë©”ì‹œì§€ í™•ì¸
        block_keywords = ["ì ‘ì†ì´ ì œí•œ", "Robot", "ìë™ì ‘ì†", "Access Denied", "IPê°€ ì°¨ë‹¨", "ë³´ì•ˆì ˆì°¨", "ë¹„ì •ìƒì ì¸ ì ‘ê·¼"]
        if any(msg in html_raw for msg in block_keywords):
            print(f"âŒ ì°¨ë‹¨ ê°ì§€: {url} ë²„ì „ì€ í˜„ì¬ GitHub Actions í™˜ê²½ì—ì„œ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
            continue

        is_mobile = "m.ppomppu" in url
        rows = []
        
        if is_mobile:
            rows = soup.select('.list_default li') or soup.select('li.common-list-item') or soup.select('.bbsList li')
        else:
            rows = soup.select('tr.list0, tr.list1') or soup.select('tr[align="center"]')
            if not rows:
                main_table = soup.find('table', id='main_list')
                if main_table:
                    rows = main_table.find_all('tr', recursive=False)[1:]

        print(f"ğŸ” í›„ë³´ í•­ëª© {len(rows)}ê°œ ë°œê²¬.")

        if not rows:
            print(f"âš ï¸ {url}ì—ì„œ ìœ íš¨í•œ ë°ì´í„° í–‰ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. êµ¬ì¡° ë¶„ì„ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            continue

        for idx, row in enumerate(rows):
            try:
                if is_mobile:
                    title_tag = row.select_one('.title') or row.select_one('strong') or row.select_one('.subject')
                    link_tag = row.select_one('a')
                    img_tag = row.select_one('img')
                else:
                    title_tag = row.find(['font', 'span'], class_='list_title') or row.select_one('a font')
                    if not title_tag: 
                        tds = row.find_all('td')
                        if len(tds) >= 3:
                            title_tag = tds[2].find('a') # PC ë²„ì „ ì œëª© ìœ„ì¹˜
                    
                    if not title_tag: continue
                    link_tag = title_tag if title_tag.name == 'a' else title_tag.find_parent('a')
                    img_tag = row.find('img', class_='thumb_border')

                if not title_tag or not link_tag: continue

                full_title = title_tag.get_text(strip=True)
                if not full_title or len(full_title) < 5: continue

                href = link_tag.get('href', '')
                if not href: continue
                
                base_url = "https://m.ppomppu.co.kr/new/" if is_mobile else "https://www.ppomppu.co.kr/zboard/"
                link = base_url + href if not href.startswith('http') else href

                # ê³µì§€ ë° ê´‘ê³  í•„í„°ë§
                if not is_mobile:
                    num_td = row.find('td', class_='eng v_middle')
                    if num_td:
                        num_text = num_td.get_text(strip=True)
                        if num_td.find('img') or not num_text.isdigit():
                            continue

                platform = "ê¸°íƒ€"
                p_match = re.search(r'\[(.*?)\]', full_title)
                if p_match: platform = p_match.group(1)
                
                price = extract_price(full_title)
                product_name = re.sub(r'\[.*?\]', '', full_title).strip()
                product_name = re.sub(r'\(.*?\)', '', product_name).strip()
                
                # ë±ƒì§€ ë¡œì§: ê±´ìš° ì·¨í–¥(ê³¤ì¶©/ìƒë¬¼) ìš°ì„  ìˆœìœ„ ë¶€ì—¬
                badge = "NEW"
                is_gunwoo_pick = False
                if any(keyword in product_name for keyword in RECOMMENDED_KEYWORDS):
                    # ê±´ìš° ì„ í˜¸ í‚¤ì›Œë“œ ì²´í¬
                    gunwoo_keywords = ['ì‚¬ìŠ´ë²Œë ˆ', 'ì¥ìˆ˜í’ë…ì´', 'ê³¤ì¶©', 'ìƒë¬¼', 'ë„ê°', 'íŒŒë¸Œë¥´', 'í‘œë³¸', 'ê³¼í•™ì¡ì§€', 'ê³µë£¡']
                    if any(gk in product_name for gk in gunwoo_keywords):
                        badge = "ê±´ìš°&ì—„ë§ˆ ì¶”ì²œ"
                        is_gunwoo_pick = True
                    else:
                        badge = "ì—„ë§ˆ ì¶”ì²œ"
                elif price > 100000:
                    badge = "HOT"
                
                # ì´ë¯¸ì§€ ì¶”ì¶œ (Lazy Loading ëŒ€ì‘)
                img_url = ""
                if img_tag:
                    src = img_tag.get('data-original') or img_tag.get('src')
                    if src:
                        if src.startswith('//'): img_url = "https:" + src
                        elif src.startswith('/'): img_url = "https://www.ppomppu.co.kr" + src
                        else: img_url = src
                
                if not img_url:
                    img_url = f"https://placehold.co/80x80/f1f5f9/94a3b8?text={platform[:1]}"

                if is_gunwoo_pick:
                    print(f"â­ [ê±´ìš° ë§ì¶¤ í•«ë”œ ë°œê²¬!] {product_name}")

                collected_data.append({
                    "category": "í•«ë”œ",
                    "platform": platform,
                    "productName": product_name,
                    "currentPrice": str(price),
                    "originalPrice": str(int(price * 1.3)) if price > 0 else "0",
                    "badge": badge,
                    "sourceSite": "ë½ë¿Œ",
                    "link": link,
                    "image": img_url,
                    "color": get_platform_color(platform)
                })
                
                if len(collected_data) >= 40: break # ë” í’ì„±í•œ ì¡ì§€ë¥¼ ìœ„í•´ 40ê°œê¹Œì§€ ìˆ˜ì§‘
            except Exception as e:
                continue
        
        if collected_data:
            print(f"âœ… {url}ì—ì„œ {len(collected_data)}ê°œì˜ ìœ íš¨ ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ.")
            break
        else:
            print(f"âš ï¸ {url}ì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ê²½ë¡œë¥¼ ì‹œë„í•©ë‹ˆë‹¤.")
            time.sleep(random.uniform(2.0, 4.0))
            
    return collected_data

def save_to_csv(data):
    """ìˆ˜ì§‘ ë°ì´í„°ë¥¼ deals.csvë¡œ ì €ì¥í•˜ë©° ì„±ê³µ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    keys = ["category", "platform", "productName", "currentPrice", "originalPrice", "badge", "sourceSite", "link", "image", "color"]
    try:
        if not data:
            print("âš ï¸ [ERROR] ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ìµœì¢…ì ìœ¼ë¡œ 0ê°œì…ë‹ˆë‹¤. ì €ì¥ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
            sys.exit(1)

        # 'ê±´ìš°&ì—„ë§ˆ ì¶”ì²œ' ì•„ì´í…œì´ ê°€ì¥ ìœ„ë¡œ ì˜¤ê²Œ ì •ë ¬
        data.sort(key=lambda x: (x['badge'] == 'ê±´ìš°&ì—„ë§ˆ ì¶”ì²œ', x['badge'] == 'ì—„ë§ˆ ì¶”ì²œ'), reverse=True)

        with open('deals.csv', 'w', encoding='utf-8-sig', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=keys)
            writer.writeheader()
            writer.writerows(data)
        print(f"ğŸ‰ íŒŒì¼ ì €ì¥ ì„±ê³µ: deals.csvì— {len(data)}ê°œì˜ í•«ë”œì´ ê¸°ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ [CRITICAL] CSV ì €ì¥ ì‹¤íŒ¨: {e}")
        sys.exit(1)

if __name__ == "__main__":
    print("ğŸš€ [ì •ë°€ ë””ë²„ê·¸ ëª¨ë“œ] í•«ë”œ ìˆ˜ì§‘ ì—”ì§„ ê°€ë™ ì‹œì‘")
    start_time = time.time()
    
    # ë´‡ ê°ì§€ íšŒí”¼ ì§€ì—°
    time.sleep(random.uniform(2, 5))
    
    deals = collect_from_ppomppu()
    
    if deals:
        save_to_csv(deals)
    else:
        print("\nâŒ [ìµœì¢… ì‹¤íŒ¨] ëª¨ë“  ê²½ë¡œ(PC/ëª¨ë°”ì¼)ê°€ ì°¨ë‹¨ë˜ì—ˆê±°ë‚˜ ì‚¬ì´íŠ¸ êµ¬ì¡°ê°€ ì™„ì „íˆ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(1)
        
    end_time = time.time()
    print(f"â±ï¸ ì´ ì†Œìš” ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")
